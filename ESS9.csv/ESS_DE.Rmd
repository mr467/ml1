---
title: "European Survey - What is the political sentiment in Europe especially on the (online) media consumption?"
author: "Milica Pajkic and Marco Rieder"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_depth: 5
  pdf_document:
    toc: yes
    toc_depth: '5'
code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
```

# Getting the Data and installing libraries

```{r, include=FALSE}
library(ggpubr)
library(lubridate)
library(multcomp)
library(dplyr)
library(readr)
library(data.table)
library(tidyverse)
theme_set(theme_bw())
library(naniar)
library(neuralnet)
library(nnet)
library(caret)
library(gamlss.add)
library(ggplot2)
library(mgcv)
library(cowplot)
library(ISLR)
library(kernlab)
library(tidyverse)
library(car)
library(e1071)
```

```{r data import}
options(scipen=999)
```

```{r}
ess9 <- read_csv("ESS9.csv")
#making subsets of the whole dataset to only Germany
ess9_de <- subset(ess9, cntry == "DE", select =dweight:domain)
```

# 1. Introduction

The European Social Survey (ESS) is a large scale survey conducted in over 38 countries within Europe. Focusing on public attitudes and values and changes within time. This paper is evaluating the ninth version of the survey (ESS9) form 2018. The political landscape has been changed immensely after the start of the pandemic. Everyone has an opinion on everything remarkably political and does not shy away from posting it online. Furthermore, as a society we have upped the news consumption during the pandemic (see for Switzerland: <https://medien.srf.ch/-/ein-von-corona-gepragtes-jahr-srf-mit-positiver-nutzungsbilanz>). So the question that this analysis is looking to answer is: How was the political sentiment/actions during the last European Social Survey before Corona and how can interest, sentiment around politics and socio-demographic attributes contribute to the prediction of the political actions.

## 1.1 Selection of parameters

The survey is really comprehensive and consists out of 572 variables. Some of them are related to others and only answered by a subset of participants. Here is the link to the survey and their many variables: <https://ess-search.nsd.no/en/study/bdc7c350-1029-4cb3-9d5e-53f668b8fa74>

## 1.2 Goal

As already mentioned above the theme this paper is following is the of political "actions". Moreover, the consumption of political news and online posting of current affairs is of important understanding considering the inhibition threshold is bigger than just talking to your family. If someone posts something online, then the person has to calculate the cost of the post for the future social interactions. The consumption of news is also connected to the thinking, a person could also consume another media content, that is much lighter and oftentimes more positive. Seemingly logical, interest in politic should have a positive relationship to these "actions". However, also the thoughts how the state of the government, satisfaction and owns ability for politics have an influence on the "actions". Next to these more politics covered predictors, there is also the socio-demographic aspect. E.g. with age, ones interest in politics rises. There also could be a gender gap and to not forget, education. The latter corresponds to political "actions" because with a higher education, one is more inclined to be able to follow current affairs because of the knowledge instilled in him during the higher education.

This paper will be following the following structure: Firstly the cleaning of the data, as there are a lot of variables there will be only cleaning of the variable that matter for this analysis. In a next step the models will be presented. The start will be made with the linear regression, then the two GLM models "Poisson" and "Binomial". The third presented model is the GAM and the last two will be the "Neural Network" and Support Vector Machine. These models will be followed with a short conclusion.

# 2. Descriptive Statistics

```{r, collapse = TRUE}
str(ess9_de)
```

## 2.1 Cleaning of the data

```{r Your [pay/pensions/social benefits], which frequency do you know best}
#1 = weekly, 2 = monthly, 3 = annual
ess9_de$infqbst.na <- ess9_de$infqbst
ess9_de["infqbst.na"][ess9_de["infqbst.na"] >= 4] <- NA
ess9_de$infqbst.fac <- factor(ess9_de$infqbst.na)
summary(ess9_de$infqbst.fac)

##Grosspay 
ess9_de$grspnum.na <- ess9_de$grspnum
ess9_de["grspnum.na"][ess9_de["grspnum.na"] >= 666666666] <- NA
summary(ess9_de$grspnum.na)
###Multiplication
ess9_de$yearpay <- ifelse(ess9_de$infqbst %in% 1,
                          ess9_de$grspnum.na*52,
                          ifelse(ess9_de$infqbst %in% 2,
                                 ess9_de$grspnum.na*12,
                                 ess9_de$grspnum.na))
summary(ess9_de$yearpay)
```

```{r recode Variable resp. clean, results = FALSE}
#NEWS Politics time recoded
ess9_de$nwspol.na <- ess9_de$nwspol
ess9_de["nwspol.na"][ess9_de["nwspol.na"] >= 7777] <- NA
#-----------------------------------------------------------------------------------------
#Educationlevel recoding
ess9_de$eduyrs.na <- ess9_de$eduyrs
ess9_de["eduyrs.na"][ess9_de["eduyrs.na"] >= 77] <- NA
#Added "Other" also under NA bc we cannot explain what other is
#-----------------------------------------------------------------------------------------
#recode the age variable
ess9_de$age.na <- ess9_de$agea
ess9_de["age.na"][ess9_de["age.na"] >= 140] <- NA
#-----------------------------------------------------------------------------------------
#record the gender variable
ess9_de$gender <- ess9_de$gndr
ess9_de["gender"][ess9_de["gender"] >= 9] <- NA
##factor/categorical
ess9_de$gndr.fac <- factor(ess9_de$gender)
#-----------------------------------------------------------------------------------------
#clean the satisfaction with democracy works in country
ess9_de$stfdem.na <- ess9_de$stfdem
ess9_de["stfdem.na"][ess9_de["stfdem.na"] > 10] <- NA
##factor/categorical
ess9_de$sat.dem.fac <- factor(ess9_de$stfdem.na)
summary(ess9_de$sat.dem.fac)
#-----------------------------------------------------------------------------------------
#clean Boycott certain products
ess9_de$bctprd.na <- ess9_de$bctprd
ess9_de["bctprd.na"][ess9_de["bctprd.na"] > 2] <- NA
##factor/categorical
ess9_de$boycott.fac <- factor(ess9_de$bctprd.na)
#-----------------------------------------------------------------------------------------
#clean left-right scale 0 =l / 10 = r
ess9_de$polscale.na <- ess9_de$lrscale
ess9_de["polscale.na"][ess9_de["polscale.na"] > 10] <- NA
#-----------------------------------------------------------------------------------------
#clean fair chance to participate in politics in yr country (5er scale)
ess9_de$fairchance <- ess9_de$frprtpl
ess9_de["fairchance"][ess9_de["fairchance"] > 6] <- NA
##factor/categorical
ess9_de$fairchance.fac <- factor(ess9_de$fairchance, levels=1:5, labels=c("not at all", "very little", "some", "a lot", "a great deal"))
#-----------------------------------------------------------------------------------------
#clean polinteresse (4er scale)
ess9_de$polinteress <- ess9_de$polintr
ess9_de["polinteress"][ess9_de["polinteress"] > 6] <- NA
##factor/categorical
ess9_de$interest.fac <- factor(ess9_de$polinteress, levels=1:4, 
                               labels=c("very", "quite", "hardly", "none at all"))
###order differently
ess9_de$interest.fac <- ordered(ess9_de$interest.fac, 
                                levels = c("none at all", "hardly", "quite", "very"))
ess9_de$interest.fac  <- relevel(ess9_de$interest.fac,
                                      ref = "none at all")
#-----------------------------------------------------------------------------------------
#clean confidence in own ability to participate (5er scale)
ess9_de$ability <- ess9_de$cptppola
ess9_de["ability"][ess9_de["ability"] > 6] <- NA
##factor/categorical
ess9_de$ability.fac <- factor(ess9_de$ability, levels=1:5, labels=c("not at all", "a little", "quite", "very", "completely"))
ess9_de$ability.fac <- ordered(ess9_de$ability.fac, 
                                levels = c("not at all", "a little", "quite", "very",
                                "completely"))
ess9_de$ability.fac  <- relevel(eess9_de$ability.fac,
                                      ref = "not at all")
summary(ess9_de$ability.fac)
#-----------------------------------------------------------------------------------------
#1 = yes / 2 = no / 3 = not eligble
ess9_de$vote.fac <- factor(ess9_de$vote, levels = 1:3, labels = c("Yes", "No", "Not eligible"))
ess9_de["vote.fac"][ess9_de["vote.fac"] >= 4] <- NA
summary(ess9_de$vote.fac)
#-----------------------------------------------------------------------------------------
#post something online in the last 12 month
ess9_de$postonline <- factor(ess9_de$pstplonl)
ess9_de["postonline"][ess9_de["postonline"] > 5] <- NA
ess9_de$postonline<-ifelse(ess9_de$postonline==1,1,0)
summary(ess9_de$postonline)
summary(as.factor(ess9_de$postonline))
summary(as.factor(ess9_de$pstplonl))
#-----------------------------------------------------------------------------------------
##Political system allows people to have a say in what government does 1 = no
ess9_de$gov.allows <- ess9_de$psppsgva
ess9_de["gov.allows"][ess9_de["gov.allows"] > 5] <- NA
ess9_de$gov.allows <- factor(ess9_de$gov.allows)
summary(ess9_de$gov.allows)
#-----------------------------------------------------------------------------------------
#Trust in country's parliament 0 = no trust
ess9_de$trustparl <- ess9_de$trstprl
ess9_de["trustparl"][ess9_de["trustparl"] > 10] <- NA
summary(as.factor(ess9_de$trustparl))
```

# 3. Models

## 3.1 Linear Model

This chapter will be focused on the continous variable *nwspol.* The question in the survey was: *On a typical day, about how much time do you spend watching, reading or listening to news about politics and current affairs?\
*The older the person, the more they watch the news. The same hypothesis can be made for *education, satisfaction with democracy, confidence in own ability to participate and interest in politics*.

```{r all variables that i want to include, collapse=TRUE}
#DV
summary(ess9_de$nwspol.na)
#predictorvariables
summary(ess9_de$eduyrs.na)
summary(ess9_de$gndr.fac)
summary(ess9_de$age.na)
summary(ess9_de$stfdem.na)
summary(ess9_de$sat.dem.fac)
summary(ess9_de$ability)
summary(ess9_de$ability.fac)
summary(ess9_de$interest.fac)
summary(as.factor(ess9_de$polinteress))
```

```{r create a DV where no outlier}
ess9_de$nwspol.outlier <- ess9_de$nwspol.na
ess9_de["nwspol.outlier"][ess9_de["nwspol.outlier"] >= 400] <- NA
```

```{r create a subset of data with only the variables mentioned above}
ess9_linear <- ess9_de[, c("nwspol.na", "age.na", "gndr.fac", "eduyrs.na", 
                           "stfdem.na", "ability", "ability.fac", "polinteress", "interest.fac", "sat.dem.fac")]
ess9_linear <- ess9_linear[complete.cases(ess9_linear),]
```

### Graphical analysis

```{r boxplots for the categorial variables w/ outliers and without outliers}
par(mfrow=c(2,3))
boxplot(nwspol.na ~ gndr.fac, data = ess9_linear)
boxplot(nwspol.na ~ ability.fac, data = ess9_linear)
boxplot(nwspol.na ~ interest.fac, data = ess9_linear)

boxplot(nwspol.na ~ gndr.fac, data = ess9_linear, outline = FALSE)
boxplot(nwspol.na ~ ability.fac, data = ess9_linear, outline = FALSE)
boxplot(nwspol.na ~ interest.fac, data = ess9_linear, outline = FALSE)
```

This plot shows in the upper half *news consumption* variable with outliers. As can be seen, there are a lot of outliers. In the second half of the plot, there are no outliers and there can bee seen an increase in news consumption (*interest in politics and confidence in ability)* with every step.

```{r}
gg_age.1 <- ggplot(data = ess9_de,
       mapping = aes(y = nwspol.na,
                     x = age.na))+
  geom_point()+ggtitle("Plot of daily News Consumption \nby age with outlier") +
  xlab("Age") + ylab("News Consumption in Minutes")
  
##
gg_age.1 <- gg_age.1 +
  geom_smooth()+
  ylim(0,460)

gg_age.2 <- ggplot(data = ess9_de,
       mapping = aes(y = nwspol.outlier,
                     x = age.na))+
  geom_point()+ggtitle("Plot of daily News Consumption \nby age without outlier") +
  xlab("Age") + ylab("News Consumption in Minutes")
  
##
gg_age.2 <- gg_age.2 +
  geom_smooth()+
  ylim(0,460)

```

```{r}
gg_edu.1 <- ggplot(data = ess9_linear,
       mapping = aes(y = nwspol.na,
                     x = eduyrs.na))+
  geom_point()+ggtitle("Plot of daily News Consumption \nby age without outlier") +
  xlab("Education in Years") + ylab("News Consumption in Minutes")
  
##
gg_edu.1 <- gg_edu.1 +
  geom_smooth()+
  ylim(0,100)

gg_edu.2 <- ggplot(data = ess9_de,
       mapping = aes(y = nwspol.outlier,
                     x = eduyrs.na))+
  geom_point()+
  ggtitle("Plot of daily News Consumption \nby age without outlier") +
  xlab("Education in Years") + ylab("News Consumption in Minutes")
  
##
gg_edu.2 <- gg_edu.2 +
  geom_smooth()+
  ylim(0,100)

plot_grid(gg_age.1, gg_age.2, gg_edu.1, gg_edu.2,
          ncol = 2, nrow = 2)
```

Interpretation:\
[**Age:**]{.underline} The relationship between age and news consumption is not at every point positively linear. It starts to grow from the age smallest age (15y) to approximitely 25 and then it stagnates till around the age 50 and then the news consumption grows with every year. This can be explained that news consumption is not that important during the time between the ages 25 to 50 because of family matters such as raising children or focusing on career. Afterwards or beforehand the obligations are lighter.\
[**Education in years:**]{.underline} there is a small positive slope. This also confirms the hypothesis that with each additional educational year ones ability in understanding of current affairs is heightend and therefore one is more interested in news and consumes it more frequently. One of the reasons is the ability to understand it.

### Fitting Model

```{r linear Regression}
lm_news.0 <- lm(nwspol.na ~ age.na, data = ess9_linear)
summary(lm_news.0)
```

```{r}
par(mfrow=c(1,2))
plot(nwspol.na ~ age.na, data = ess9_linear,
     ylim = c(0, 500))
#the ylim was chosen what makes the most sense over 600min watching news equals to 8h/daily
grid(ny = 20)
##
abline(lm_news.0,
       col = "red", lwd=2)
#Zoom in 
plot(nwspol.na ~ age.na, data = ess9_linear,
     ylim = c(0, 100))
##
grid()
##
abline(lm_news.0,
       col = "red", lty = "dashed")
```

[**Interpretation**]{.underline}: age is a highly significant predictor. It is a positive relationship to the news consumption in minute. The p-Value is \<0.05. For every additional year a person nearly 1 minute (0.97) is added to the news consumption. This does not dismis the hypothesis that with every additional year, a person is following the news. There is the common knowledge that the older population is more likely to vote and that young people are more focused on other life topics.

#### Adding additional predictors

```{r}
lm_news.1 <- lm(nwspol.na ~ age.na + ability.fac, data = ess9_linear)
summary(lm_news.1)
```

```{r}
confint(lm_news.1)
```

```{r}
drop1(lm_news.1, test = "F")
```

[**Interpretation**]{.underline}: the Variable *Confidence in ability* might have an influence on the dependent variable as it is significant in the single term deletions.

```{r}
ph.test.THSD <- glht(lm_news.1,
                     linfct = mcp(ability.fac = "Tukey"))
summary(ph.test.THSD)
```

```{r}
par(mar = c(5.1,7.5,4.1,2.1))
plot(ph.test.THSD)
```

[**Interpretation**]{.underline}: When comparing the different self assumed levels of *confidence in ones ability* it is observable that the polar opposites *completely* and *not at all* have significant difference (p\<.05) and the next biggest difference *completely* and *a little* are also significant. The others have a lower level of significants or none at all.

```{r}
lm_news.2 <- lm(nwspol.na ~ eduyrs.na + age.na + gndr.fac + stfdem.na + ability.fac + interest.fac, data = ess9_linear)
summary(lm_news.2)
```

[**Interpretation:**]{.underline} Age and two expressions of the predictor variable *interest in politics* show signifcant values. *Interest* is here only significant in terms of the reference level. This linear regression also shows a higher adjusted R2 (0.085) then the one with the two predictors. However, it is still a small value and the model explains roughly 8% of the variations of the data.

```{r}
confint(lm_news.2)
```

```{r}
cis.lm_news.2 <- confint(lm_news.2)
##
## 2) plot estimates
par(mar = c(4,9,2,2))
plot(y = 1:12,
     x = rev(coef(lm_news.2)),
     xlim = c(-20, 80),
     main = "Conifidence Intervall of predictors",
     xlab = "Estimated coefficients",
     ylab = "",
     axes = FALSE)
box()
axis(side = 2, at = 1:12,
     labels = rev(names(coef(lm_news.2))), 
     las = 2)
axis(side = 1)

segments(x0 = rev(cis.lm_news.2[, "2.5 %"]),
         x1 = rev(cis.lm_news.2[, "97.5 %"]),
         y0 = 1:12,
         y1 = 1:12)
abline(v = 0, lty = "dashed")
```

***Interaction: Age \* ability***

The background to this interaction: With every additional year on this earth one grows in his confidence in the own ability to participate in the political landscape. So therefore, the level of confidence in ones ability is dependent/varies on the age.

```{r}
lm_news.3 <- lm(nwspol.na ~ eduyrs.na + age.na * ability.fac + gndr.fac + stfdem.na + interest.fac, data = ess9_linear)
summary(lm_news.3)
```

```{r}
drop1(lm_news.3)
```

[**Interpretation**]{.underline}: Nothing is significant, not even the interaction. The hypothesis on the interaction has to be dismissed. Also the adjusted R2 has not increased (a lot), therefore, this interaction is not useful.

```{r}
confint(lm_news.3)
```

```{r}
cis.lm_news.3 <- confint(lm_news.3)
##
## 2) plot estimates
par(mar = c(4,10,2,2))
plot(y = 1:16,
     x = rev(coef(lm_news.3)),
     xlim = c(-20, 100),
     xlab = "Estimated coefficients",
     ylab = "",
     axes = FALSE)
box()
axis(side = 2, at = 1:16,
     labels = rev(names(coef(lm_news.3))), 
     las = 2)
axis(side = 1)

segments(x0 = rev(cis.lm_news.3[, "2.5 %"]),
         x1 = rev(cis.lm_news.3[, "97.5 %"]),
         y0 = 1:16,
         y1 = 1:16)
abline(v = 0, lty = "dashed")
```

The interaction is not significant. Therefore, let's focus on the *interest in politics* variable

```{r}
ph.test.THSD.1 <- glht(lm_news.3,
                     linfct = mcp(interest.fac = "Tukey"))
summary(ph.test.THSD.1)
par(mar = c(5.1,10.5,2.1,1.1))
plot(ph.test.THSD.1)
```

```{r}
ggplot(data = ess9_linear,
       mapping = aes(y = nwspol.na,
                     x = age.na)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(. ~ interest.fac)+
  ylim(0,250)+
  ylab("News Consumption in Minutes")+
  ggtitle("News Consumption Daily by Age: Categorized by Political Interest")+
  xlab("Age")
```

[**Interpretation**]{.underline}: the different stages of political interest indicate a different usage of news according to the age. While the lowest level of political interest shows a positive relationship between news consumption and age, it has the the second smallest slope. The most interest category expression has the biggest slope over the lifetime.

### Fitted Values and Residuals

#### Fitted Values

```{r fitted values}
fit_lm_news.0 <- fitted(lm_news.0)
str(fit_lm_news.0)
head(fit_lm_news.0)
x.fit.0 <- unique(fit_lm_news.0) 
```

There are 185 unique fitted values from the first linear regression.

```{r fitted values plot lm1}
par(mfrow=c(1,2))
plot(nwspol.na ~ age.na, data = ess9_linear, 
     main = "Minutes spent on Political News", 
     col = "darkgrey",
     ylim = c(0, 500))
points(fit_lm_news.0 ~ age.na, 
       col = "purple", 
       pch = 19, 
       data = ess9_linear)
abline(lm_news.0, col = "black")

plot(nwspol.na ~ age.na, data = ess9_linear, 
     main = "Minutes spent on Political News", 
     col = "darkgrey",
     ylim = c(0, 110))
points(fit_lm_news.0 ~ age.na, 
       col = "purple", 
       pch = 19, 
       data = ess9_linear)
abline(lm_news.0, col = "black")
```

#### Residuals

```{r}
resid.news.0 <- resid(lm_news.0)
##
length(resid.news.0 )
head(resid.news.0 )
```

```{r}
set.seed(20) ## for reproducibility 
id <- sample(x = 1:2296, size = 20) 
resid.news.0[id]
```

```{r}
fit_lm_news.0[id]
```

```{r}
plot(nwspol.na ~ age.na, data = ess9_linear,
     main = "Minutes spent on Political News",
     col = "lightgray")
##
abline(lm_news.0)
##
points(nwspol.na ~ age.na, data = ess9_linear[id, ], col = "red")
```

### Predicted values

#### one predictor variable

```{r}
new.data.news <- data.frame(age.na = c(33,56, 80, 21))
pred.new.news <- predict(object = lm_news.0, newdata = new.data.news)

plot(nwspol.na ~ age.na, data = ess9_linear,
     main = "Minutes spent on Political News",
     col = "lightgray",
      ylim=c(0, 200))
abline(lm_news.0)
points(x = new.data.news$age.na,
       y = pred.new.news,
       col = "purple",
       pch = 19, cex = 1.5)
```

```{r}
pred.new.news.ci <- predict(object = lm_news.0,
                            interval = "prediction",
        newdata = new.data.news)
pred.new.news.ci
```

```{r}
plot(nwspol.na ~ age.na, data = ess9_linear,
     main = "Minutes spent on Political News",
     col = "lightgray",
      ylim=c(0, 800))
abline(lm_news.0)
##
points(x = new.data.news$age.na,
       y = pred.new.news.ci[, "fit"], 
       col = "purple",
       pch = 19, cex = 1.5)
##
segments(x0 = new.data.news$age.na, 
         x1 = new.data.news$age.na,
         y0 = pred.new.news.ci[, "lwr"],
         y1 = pred.new.news.ci[, "upr"],
         lwd = 2,
         col = "purple")
```

## 3.2 GLM Poisson

The goal of this chapter is to apply a generalized linear model of the poisson type on the ESS9 data set. The poisson model is applied to count data, in this case the information of how many minutes the participants spend per day for consuming media, such as newspaper, TV new shows or online resources.

In this chapter the model is used to simulate the data, based on the survey data. Getting a simulation of the minutes according to a selected subset of variables from the study.

First the data is cleaned and prepared for using it. A subset of the data is used, containing social and demographic variables which should help to model the news consumption of a person. These parameters are used:

Depended variable:

-   How much politics are you watching ("nwspol")

Independent variables:

1.  Interest in politics ("polintr)
2.  Trust into the current parlament ("trstprl")
3.  Highest level of education ("eisced")
4.  Years of education ("eduyrs")
5.  Satisfaction with the general economical situation ("stfeco")
6.  Satisfaction with the current government ("stfgov")
7.  Satisfaction with the democratic system ("stfdem")
8.  Gender ("gndr")
9.  Age ("agea")
10. Level of religiouse believes ("rlgdgr")
11. Time spent online in 5 categorical values("netusoft")
12. Possibility for political participation ("psppsgva")
13. Yearly gross income (combination of two factors into a new one - "yrpy")

### 3.2.1 Data preparation

The data have to be prepared and transformed. For poisson count data are needed for the predictive variable. The time in minutes is modeled therefore.

```{r data preparation for models, include=TRUE}
# Setting NA values correct for the used parameters replace with NA replace function from naniar package. As each variable has a different NA setting, it is specified for each variable.

ess9_prep <- ess9 %>%
  replace_with_na(replace = list(nwspol =
                                   c(6666, 7777, 8888, 9999),
                                 polintr = c(7,8,9),
                                 trstprl = c(77,88,99),
                                 eisced = c(77,88,99),
                                 eduyrs = c(77, 88, 99),
                                 stfeco = c(77, 88, 99),
                                 stfgov = c(77, 88, 99),
                                 stfdem = c(77, 88, 99),
                                 gndr = 9,
                                 agea = 999,
                                 rlgdgr = c(77, 88, 99),
                                 netustm = c(6666, 7777, 8888, 9999),
                                 netusoft = c(7,8,9),
                                 psppsgva = c(7,8,9),
                                 grspnum = c(666666666,777777777,888888888,999999999),
                                 infqbst = c(6,7,8,9)
                                 ))

#testing if change has worked and how many NA we have - for four examples

sum(is.na(ess9_prep$nwspol))
sum(is.na(ess9_prep$eduyrs))
sum(is.na(ess9_prep$stfgov))
sum(is.na(ess9_prep$netusoft))

# The variable "grspnum" is depended on the variable "infqbst." As "infqbst" sets the period of the payment and "grpsnum" is the payment amount for the defined period. To standardize it on a yearly gross payment it needs a nested ifelse statement.

ess9_prep$yrpy <- ifelse(ess9_prep$infqbst %in% 1,
                                ess9_prep$grspnum*52,  
                            ifelse(ess9_prep$infqbst %in% 2,
                                ess9_prep$grspnum*12, 
                                ess9_prep$grspnum))

```

Subset data for this task, to the defined 14 variables in total. The rows with NA are dropped, as the data set is large enough for dropping theses values.

```{r data subset and NA, include=TRUE}
# defining subset for study and models. These factors will be used in the Poisson and Neural Network models below. 
ess9_subset <- c("nwspol", "polintr", "trstprl", "eisced", "eduyrs","stfeco", "stfgov", "stfdem", "gndr", "agea","rlgdgr","netusoft", "psppsgva", "yrpy")

#subsetting the dataset with the defined parameters
ess9_prep <- ess9_prep[ess9_subset]

# drop NA for the columns used for the poisson model
ess9_prep <- ess9_prep %>% drop_na((ess9_subset))

#keep data for AMM part as numeric values - saved for later
ess9_prep_num <- ess9_prep
```

```{r data factorization, include=TRUE}

# set of parameters which are categorical variables
factors <- c("polintr","trstprl", "eisced", "stfeco", "stfgov", "stfdem", "gndr", "rlgdgr", "psppsgva", "netusoft")

# applying factorization of variables
ess9_prep[factors] <- lapply(ess9_prep[factors], as.factor)
#show data after preparation
str(ess9_prep)

```

The plot shows the media consumption for male and female to gain a quick overview. Males have a higher mean and the variance of values between the first and third quantile is larger as well in comparison.

```{r plotting of media consumaption and gender}
# Use cleaned and factorized data for the Poisson model
ess9_poisson <- ess9_prep

ggplot(data = ess9_poisson, mapping = aes(y = nwspol,x = gndr)) +
  geom_boxplot() +
  ggtitle("Media consumption in minutes compared to Gender (Zoomed In)")+
  ylab("media consumption in minutes") +
  xlab("Gender") +
  coord_cartesian(ylim = quantile(ess9_poisson$nwspol, c(0.1, 0.9))) # large outliers are cropd out to indicate variance of male and female
```

The second plot indicates the frequency of internet usage and the media consumption. The mean of the two lower frequencies ("never" and "only occasionally") have higher values for media consumption.

```{r plotting of media consumaption and frequency of internet usage, collapse=TRUE}

ggplot(data = ess9_poisson, mapping = aes(y = nwspol,x = netusoft)) +
  geom_boxplot() +
  ggtitle("Media consumption in minutes compared to frequency of internet usage (Zoomed In)")+
  ylab("media consumption in minutes") +
  xlab("frequency of internet usage") +
  coord_cartesian(ylim = quantile(ess9_poisson$nwspol, c(0.1, 0.9))) # large outliers are cropt out to indicate variance of male and female

```

### 3.2.2 Fitting the poisson model

Using the parameter specified above to model the consumption. Using the subset variables of the survey.

```{r Poisson model fitting}
# fitting the model
glmP_news <- glm(nwspol ~ polintr + eisced + trstprl+ 
                   eduyrs + netusoft + stfeco + stfgov + 
                   stfdem + gndr + agea + rlgdgr +yrpy,
                 family = "poisson", ## we specify the distribution!
                 data = ess9_poisson)

summary(glmP_news)
```

The summary shows the residual deviance as 1532064 on 16960 degrees of freedom. This indicates an overdispersion as the difference between these two numbers is large. For an non-overdispersed result the should be similar or the same.

To compare the model for the two gender, the coefficient can be calculated.

```{r Poisson model coef}
coef(glmP_news)

exp(coef(glmP_news)["gndr2"]) %>% round(digits = 4)
```

Female do consume approx. 10% less media compared to male participants.

### 3.2.3 Simulation

Now we simulate with our model the average media consumption for Females and Males.

```{r poisson}

set.seed(2) # for reproducibility
#simulate the data from glm poisson
sim.data.ess9.Poisson <- simulate(glmP_news)
##

NROW(sim.data.ess9.Poisson)
head(sim.data.ess9.Poisson)

#plot data as bar plot, with gender as factor to get two groups to compare, without factoring only one plot would show.
ggplot(mapping = aes(y = sim.data.ess9.Poisson$sim_1,
                     x = ess9_poisson$gndr)) +
  geom_boxplot() +
  geom_hline(yintercept = 0) +
  ylab("simulated media consumption \n(assuming Poisson dist)") +
  xlab("Gender") +
  coord_cartesian(ylim = quantile(ess9_poisson$nwspol, c(0.1, 0.9))) # large outliers are removed to indicate variance of male and female

```

The simulated data look similar as the real data based of the survey. The variance is smaller for the simulated one. The higher mean and the higher variance for the male group is indicated in the real data as well as in the simulated data.

### 3.2.4 GLM Quasi-Poisson

In chapter 3.2.2 the data showed a overdispersion for the poisson model. This isn't unusual and can be handled by the quasipoisson model type. The value for the dispersion parameter of 206.3327 indicates a much faster increase of variance than linearly.

```{r quasipoisson}
glmQ_news <- glm(nwspol ~ polintr + eisced + trstprl+ eduyrs + netusoft + stfeco + stfgov +
                   stfdem + gndr + agea + rlgdgr +yrpy,
                 family = "quasipoisson", ## we specify the distribution!
                 data = ess9_poisson)
summary(glmQ_news)
```

```{r quasipoisson - Anova for Gender}

# Checking if Gender plays a role in the quasipoisson model. With the ANOVA function.
glmQ_news_noGender <- update(glmQ_news, . ~ . - gndr)
anova(glmQ_news, glmQ_news_noGender, test = "F")
```

Yes, Gender plays a role for the quasi poisson model. This can be assured with this test.

```{r quasipoisson - Anova for stfdem}

# Checking if Gender plays a role in the quasipoisson model. With the ANOVA function.
glmQ_news_noGender <- update(glmQ_news, . ~ . - stfdem)
anova(glmQ_news, glmQ_news_noGender, test = "F")
```

To compare it with the variable of "stfdem" about how satisfied the participants of the survey are about how the democracy in their country works. This variable doesn't play a role to predict the media consumption according to the quasipoisson model.

The results can be concluded that according to the models there is some evidence, that the factors Interest in politics, age, and gender are influencing the media consumption.

## 3.3 GLM Binomial

For the binary data we are using the following question from the survey: *There are different ways of trying to improve things in [country] or help prevent things from going wrong. During the last 12 months, have you done any of the following? Have you\... \...posted or shared anything about politics online, for example on blogs, via email or on social media such as Facebook or Twitter?*

```{r subset of dataframe because of differen NA}
ess9_binary <- ess9_de[, c("postonline", "age.na", "interest.fac", "gov.allows", "trustparl", "polscale.na", "eduyrs.na", "ability.fac", "sat.dem.fac", "boycott.fac", "vote.fac")]
ess9_binary.na <- ess9_binary[complete.cases(ess9_binary),]
```

```{r, collapse = TRUE}
str(ess9_binary.na)
```

### Graphical Analysis

```{r, collapse=TRUE}
pairs(postonline ~ age.na + interest.fac + gov.allows +
trustparl + polscale.na +
ability.fac + sat.dem.fac + boycott.fac + vote.fac, data = ess9_binary.na, upper.panel = panel.smooth)
```

```{r EDA}

g1 <- ggplot(data = ess9_binary.na,
       mapping = aes(y = postonline,
                     x = age.na))+
  geom_point()+
  geom_smooth(method = "glm", 
              se = FALSE,
              method.args = list(family = "binomial")) 

g2 <- ggplot(data = ess9_binary.na,
       mapping = aes(y = postonline,
                     x = eduyrs.na))+
  geom_point()+
  geom_smooth(method = "glm", 
              se = FALSE,
              method.args = list(family = "binomial")) 

g3 <- ggplot(data = ess9_binary.na,
       mapping = aes(y = postonline,
                     x = interest.fac))+
  geom_point()+
  geom_smooth(method = "glm", 
              se = FALSE,
              method.args = list(family = "binomial")) 

g4 <- ggplot(data = ess9_binary.na,
       mapping = aes(y = postonline,
                     x = ability.fac))+
  geom_point()+
  geom_smooth(method = "glm", 
              se = FALSE,
              method.args = list(family = "binomial")) 

g5 <- ggplot(data = ess9_binary.na,
       mapping = aes(y = postonline,
                     x = boycott.fac))+
  geom_point()+
  geom_smooth(method = "glm", 
              se = FALSE,
              method.args = list(family = "binomial")) 

g6 <- ggplot(data = ess9_binary.na,
       mapping = aes(y = postonline,
                     x = vote.fac))+
  geom_point()+
  geom_smooth(method = "glm", 
              se = FALSE,
              method.args = list(family = "binomial")) 

plot_grid(g1, g2, g3, g4, g5, g6,
          ncol = 2, nrow = 3)
```

### Fitting the binary model (logistic regression)

If someone posts online is dependent on the age of the person. Older people are not that tech-savy and therefore, have a higher inhibition to post online. On the other hand, young people grew up with social media and therefore are more likely to post political induced things.

```{r glm model for binary data}
glm_pol.0 <- glm(postonline ~ age.na, data = ess9_binary.na,
                 family = "binomial")
summary(glm_pol.0)
```

```{r}
glm_pol.1 <- glm(postonline ~ age.na + eduyrs.na + interest.fac + boycott.fac + vote.fac, data = ess9_binary.na,
                 family = "binomial")
summary(glm_pol.1)
exp(coef(glm_pol.1)["age.na"])
exp(coef(glm_pol.1)["eduyrs.na"])
```

```{r}
exp(coef(glm_pol.1))
```

Interpretation: By increasing the age by one year, the risk in odds will be increasing by approx. 1 time to post something political online.\
The odds for posting online by having

```{r}
summary(ess9_de$interest.fac)
```

### Estimating the performance of a binary model

#### simple binary model

```{r, collapse = TRUE}
fitted(glm_pol.0) %>% round(digits = 2)
```

```{r}
fitted_glm.pol.0.disc <- ifelse(fitted(glm_pol.0) < 0.3, 
                                yes = 1, no = 0)
head(fitted_glm.pol.0.disc)
summary(as.factor(fitted_glm.pol.0.disc))
```

```{r}
d.obs.fit.glm.pol <- data.frame(obs = ess9_binary.na$postonline,                            
                                fitted = fitted_glm.pol.0.disc) 
table(d.obs.fit.glm.pol)
```

```{r}
table(obs = d.obs.fit.glm.pol$obs,
      fit = d.obs.fit.glm.pol$fitted)
```

```{r}
table(obs = d.obs.fit.glm.pol$obs,
      fit = d.obs.fit.glm.pol$fitted) %>%
  prop.table() %>%
  round(digits = 2)
```

[**Interpretation**]{.underline}: The table for the simple binary model (only one predictor) reveals that only 27 % of the observed data points have been correctly categorized (0 = did not post online; 1 = posted online). One reason for this low correct labeling could be the 0.3 used as a "cutoff" tool. However, by using the usually utilized 0.5 as a "cutoff" number there would not have been any observation for the level posted online. This is a trade-off the authors of this paper are aware of and it is a limitation of this analysis. The reason behind this predictor variable is the less "tech-saviness" of the older generation and therefore a less probability of them posting online about political matters.

#### more complex binary model

```{r, collapse = TRUE}
fitted(glm_pol.1) %>% round(digits = 2)
```

```{r}
fitted_glm.pol.1.disc <- ifelse(fitted(glm_pol.1) < 0.5, 
                                yes = 1, no = 0)
head(fitted_glm.pol.1.disc)
summary(as.factor(fitted_glm.pol.1.disc))
```

```{r}
d.obs.fit.glm.pol.2 <- data.frame(obs = ess9_binary.na$postonline,                            
                                fitted = fitted_glm.pol.1.disc) 
table(d.obs.fit.glm.pol.2)
```

```{r}
table(obs = d.obs.fit.glm.pol.2$obs,
      fit = d.obs.fit.glm.pol.2$fitted)
```

```{r}
table(obs = d.obs.fit.glm.pol.2$obs,
      fit = d.obs.fit.glm.pol.2$fitted) %>%
  prop.table() %>%
  round(digits = 2)
```

[**Interpretation**]{.underline}: Meanwhile with the more complex binary model (more than one predictor) and the usage of the right number for the "cutoff" and the properly estimated data points are at 20%. This is also an under performing model.

## 3.4 GAM

In this chapter a generalized additive model (GAM) is applied to the data set. First the data is visually analyzed and checked. The variables don't show a strong relation ship and the line is mostly horizontal.

```{r GAM peperation}
ess9_GAM <- ess9_prep

# Multi plots for News Consumption

pairs((nwspol) ~ . , data = ess9_GAM, pch = ".", upper.panel = panel.smooth)
#plotting news consumption and highest level of education (standardized)
ggplot(data = ess9_GAM ,mapping = aes(y = nwspol ,
                                  x = eisced)) +
    ggtitle("Media consumption and level of education") +
  ylab("Media consumption in minutes") +
  xlab("Highest achieved level of education") +
  geom_boxplot()


# ploting news and age of participants
ggplot(data = ess9_GAM ,mapping = aes(y = nwspol ,
                                  x =  (agea))) +
      ggtitle("Media consumption and age")+
  ylab("Age") +
  xlab("Highest achieved level of education") +
  geom_point()+
  geom_smooth()

#plotting news and education

ggplot(data = ess9_GAM ,mapping = aes(y = nwspol ,
                                  x =  (eduyrs))) +
  geom_point()+
      ggtitle("Media consumption and years of education")+
  ylab("media consumption in minutes") +
  xlab("Years of education") +
  geom_smooth()


ggplot(data = ess9_GAM ,mapping = aes(y = nwspol ,
                                  x =  (yrpy))) +
      ggtitle("Media consumption and yearly gross income")+
  ylab("media consumption in minutes") +
  xlab("yearly gross income") + 
  geom_point()+
  geom_smooth()
```

```{r GAM}
GAM.netusoft <- gam((as.numeric(netusoft)) ~ yrpy + 
                      s(nwspol) + s(agea) + 
                      s(eduyrs, k= 1),
                data = ess9_poisson)

summary(GAM.netusoft)
plot(GAM.netusoft, residuals = TRUE, cex = 2)
```

The number of education years has a "edf" value of 1.9 this means it isn't linear but has the lowest value of the three parameter and the model can be refitted and removing the smoothing factor.

```{r}
GAM.netusoft2 <- gam((as.numeric(netusoft)) ~ yrpy + 
                      s(nwspol) + s(agea) + 
                      eduyrs,
                data = ess9_poisson)

summary(GAM.netusoft2)
plot(GAM.netusoft2, residuals = TRUE, cex = 2)

```

The parameter age and news consumption can be compared for the two GAM models. It is visible that both are non-linear and only age changes in comparison of the two models.

## 3.5 Neural Network

Additional to "classic" linear models and GLM options, there are neural networks for analyzing and predicting data.

Within this chapter two types of neural network model are applied to two different questions.

1.  Predicting the values for the continuous variable
2.  Predicting the values for the categorical variable indicating the 5 levels of frequency of usage of internet

### 3.5.1 continious variable

```{r data import for neural network}

ess9_ann<- ess9_prep_num

str(ess9_ann)

```

#### Prepare for Training

```{r preparation}
set.seed(123)
ess9_ann[factors] <- lapply(ess9_ann[factors], as.numeric)

indices <- createDataPartition(ess9_ann$nwspol, p = 0.8, list = FALSE)
train <- ess9_ann %>% slice(indices)
test <- ess9_ann %>% slice(-indices)

boxplot(train$nwspol, test$nwspol, ess9_ann %>% sample_frac(0.2) %>% pull(nwspol), outline = FALSE)
```

```{r scaling of data}
max <- apply(ess9_ann, 2, max)
min <- apply(ess9_ann, 2, min)
ess9_ann_scaled <- as.data.frame(scale(ess9_ann, center = min, scale = max - min))
train_scaled <- ess9_ann_scaled %>% slice(indices)
test_scaled <- ess9_ann_scaled %>% slice(-indices)
```

#### Fit the Network

```{r NN model fitting}


set.seed(42)
ess9_nnet = neuralnet(nwspol ~ polintr + eisced + trstprl+ eduyrs + netusoft + 
                        stfeco + stfgov + stfdem + gndr + agea + rlgdgr +yrpy,
                      train_scaled, hidden = c(5,2) , linear.output = FALSE)
plot(ess9_nnet)
```

#### Predict the test set

```{r predict, include=FALSE}
pred_scaled <- compute(ess9_nnet, test_scaled %>% dplyr::select(-nwspol))
pred <- pred_scaled$net.result * (max(ess9_ann$nwspol) - min(ess9_ann$nwspol)) + min(ess9_ann$nwspol)
pred
```

```{r plot comparsion of real and predicated data}
plot(test$nwspol, pred, col='blue', pch=16, ylab = "predicted nwspol NN", xlab = "real nwspol")
abline(0,1)
```

And calculate the RMSE

```{r RMSE}
sqrt(mean((test$nwspol - pred)^2))
```

#### Redo with `caret` and Cross Validation

```{r caret applied again, collapse=TRUE, message=FALSE, warning=FALSE}
set.seed(42)
tuGrid <- expand.grid(.layer1=c(1:2), .layer2=c(0,2), .layer3=c(0))


trCtrl <- trainControl(
  method = 'repeatedcv', 
  number = 4, 
  repeats = 8, 
  returnResamp = 'final'
)

models <- train(
  x = ess9_ann %>% dplyr::select(-nwspol),
  y = ess9_ann_scaled %>% pull(nwspol),
  method = 'neuralnet', metric = 'RMSE', 
  linear.output = FALSE,
  # be careful, does only work on x!
  preProcess = c('center', 'scale'),
  tuneGrid = tuGrid,
  trControl = trCtrl
)
```

```{r message=FALSE, warning=FALSE}
plot(test$nwspol, pred, col='blue', pch=16, ylab = "predicted rating NN", xlab = "real rating")
abline(0,1)


```

```{r}
plot(models)
```

and extract the best model

```{r}
plot(models$finalModel)
```

### 3.5.2 Categorical variable

NN models can be used for categorical variables as well. In this chapter the goal is to find a classification of values to the categories. As variable the frequency of usage of the internet is used.

```{r}
ess9_ann2<- ess9_prep_num
#changing depended variable to factor
ess9_ann2$netusoft <- as.factor(ess9_ann2$netusoft)

str(ess9_ann2)
```

#### Have a quick look at the Data

```{r}
ess9_ann2 %>%
  ggplot(aes(x = yrpy, y = nwspol, color = netusoft)) +
  geom_point()
```

```{r}
ess9_ann2 %>%
  ggplot(aes(x = eduyrs, y = nwspol, color = netusoft)) +
  geom_point()
```

#### Prepare the Data for Training

```{r}
set.seed(123)
indices <- createDataPartition(ess9_ann2$netusoft, p=.85, list = F)
```

The distribution of our different prediction classes in the train and test data sets can be compared. The data shows a concentration of 4 and 5 values. The participants of this survey are often and frequently using the internet.

```{r}
ess9_ann2 %>%
  mutate(train = row_number() %in% indices) %>%
  dplyr::select(netusoft, train) %>%
  table()
```

```{r}
train <- ess9_ann2 %>%
  slice(indices)
test_in <- ess9_ann2 %>%
  slice(-indices) %>%
  dplyr::select(-netusoft)
test_truth <- ess9_ann2 %>%
  slice(-indices) %>%
  pull(netusoft)
```

#### Train the Neural Network

Call the `neuralnet` function creating a network with two hidden layer.

```{r}
set.seed(21)
ess9_ann_net <- neuralnet(netusoft ~ ., train, hidden = c(2,1))
```

Plot the resulting network including the weights

```{r}
plot(ess9_ann_net)
```

#### Make Predictions

```{r Predictions, collapse=TRUE}
test_results <- neuralnet::compute(ess9_ann_net, test_in)
test_results$net.result
```

Find class (i.e. output neuron) with the highest probability and convert this back into a factor

```{r find class, collapse=TRUE}
test_pred <- apply(test_results$net.result, 1, which.max)
test_pred <- factor(levels(test_truth)[test_pred], levels = levels(test_truth))
test_pred
```

#### Evaluate the Results

The confusion maztrix shows

```{r conf matrix}
conf_matrix <- confusionMatrix(test_truth, test_pred)
conf_matrix
```

#### Optimize Network Structure

First we need to remodel the data due to some limitations of `caret`

```{r}
xor <- model.matrix(~ netusoft, ess9_ann2)
xor[,1] <- ifelse(xor[,2] %in% 0 & xor[,3] %in% 0, 1, 0)
colnames(xor)[1] <- 'netusoft'
head(xor)
```

```{r}
ess9_ann_mod <- cbind(xor, ess9_ann2 %>% dplyr::select(-netusoft))
train_mod <- ess9_ann_mod %>% slice(indices)
```

```{r}

set.seed(142)
formula = netusoft + netusoft2 + netusoft3 + netusoft4 + netusoft5 ~ nwspol + stfdem + gndr + agea + yrpy + eduyrs
models <- train(formula, train_mod,
               method="neuralnet",
               linear.output = FALSE,
               ### Parameters for layers
               tuneGrid = expand.grid(.layer1=c(1:2), .layer2=c(0:3), .layer3=c(0)),  
               ### Parameters for optmisation
               learningrate = 0.1,  
               threshold = 0.1,     
               stepmax = 5000         
)

```

And have a look at the different models

```{r}
plot(models)

```

And try out the best model

```{r}
set.seed(42)
best_model <- neuralnet(
  formula,
  ess9_ann_mod %>% slice(indices),
  hidden = c(2,3),
  learningrate = 0.1, 
  threshold = 0.1,   
  stepmax = 20000,
  linear.output = FALSE
)

plot(best_model)

```

The error for both types of neutral network model is still high, the optimization options were limited, as changing variables lead to high computing times. Nevertheless the models predict values for the two chosen variables. The continuous model lead to better results, comparing the calculated errors.

## 3.6 Support Vector Machine

```{r, collapse=TRUE}
ess9_de$scale_cat  <- cut(ess9_de$polscale.na,
              breaks=c(-1, 4.5, 7.5, 10),
              labels=c('left', 'center', 'right'))
summary(ess9_de$scale_cat)
summary(as.factor(ess9_de$polscale.na))
ess9_de$scale_cat <- as.factor(ess9_de$scale_cat)
typeof(ess9_de$scale_cat)
summary(ess9_de$scale_cat)
```

```{r, collapse= TRUE}
d.ess9_supportvec <- ess9_de[, c("age.na", "interest.fac", "scale_cat", "eduyrs.na", "sat.dem.fac", "yearpay", "vote.fac")]
d.ess9_supportvec <- d.ess9_supportvec[complete.cases(d.ess9_supportvec),]
str(d.ess9_supportvec)
```

### Have a quick look at the Data

```{r}
d.ess9_supportvec %>%
  ggplot(aes(x = age.na, y = yearpay, color = scale_cat)) +
  geom_point() 
```

```{r}
d.ess9_supportvec %>%
  ggplot(aes(x = age.na, y = eduyrs.na, color = scale_cat)) +
  geom_point()

```

### Prepare the Data for Training

```{r}
set.seed(123)
indices <- createDataPartition(d.ess9_supportvec$scale_cat, p=.85, list = F)
```

### Create some easy Variables to access Data

```{r}
train <- d.ess9_supportvec %>%
  slice(indices)
test_in <- d.ess9_supportvec %>%
  slice(-indices) %>%
  dplyr::select(-scale_cat)
test_truth <- d.ess9_supportvec %>%
  slice(-indices) %>%
  pull(scale_cat)
```

### Train the Neural Network

```{r}
set.seed(123)
ess_de_svm <- svm(scale_cat ~ ., train, kernel = "linear", scale = TRUE, cost = 10)
summary(ess_de_svm)
```

```{r}
plot(ess_de_svm, train, eduyrs.na ~ age.na)
```

```{r}
plot(ess_de_svm, train, yearpay ~ age.na)
```

```{r}
tune.out <- tune(svm, scale_cat ~ ., data = train, 
                 kernel = "linear", ranges=list(cost=c(0.001,0.01, 0.1, 1, 5, 10, 100)))
(bestmod <- tune.out$best.model)
```

```{r}
ess_de_svm.1 <- svm(scale_cat ~ ., train, kernel = "linear", scale = TRUE, cost = 1)

plot(ess_de_svm.1, train, yearpay ~ age.na)

```

```{r}
plot(ess_de_svm.1, train, eduyrs.na ~ age.na)
```

### Make Predictions

```{r}
test_pred <- predict(ess_de_svm.1, test_in)
table(test_pred)
```

### Evaluate the Results

```{r}
conf_matrix <- confusionMatrix(test_pred, test_truth)
conf_matrix
```

**Interpretation**: the accuracy of the linear model is at a bit over 50%. It makes sense, as the descriptive plots hinted that there cannot be a straight "division" line.

### Try again with other parameters

```{r}
set.seed(123)
ess_de_svm.rad <- svm(scale_cat ~ ., train, kernel = "radial", scale = TRUE, cost = 100000)
summary(ess_de_svm.rad)
```

```{r}
plot(ess_de_svm.rad, train, yearpay ~ age.na)
```

```{r}
tune.out <- tune(svm, scale_cat ~ ., data = d.ess9_supportvec, 
                 kernel = "radial", ranges=list(cost=c(0.001,0.01, 0.1, 1, 5, 10, 100, 1000)), gamma = c(0.5, 1, 2, 3, 4))
(bestmod <- tune.out$best.model)
```

```{r}
ess_de_svm.rad.1 <- svm(scale_cat ~ ., train, kernel = "radial", scale = TRUE, cost = 1, gamma = 0.5)

```

```{r}
plot(ess_de_svm.rad.1, train, eduyrs.na ~ age.na)
```

```{r}
test_pred1 <- predict(ess_de_svm.rad.1, test_in)
table(test_pred1)
```

```{r}
conf_matrix <- confusionMatrix(test_pred1, test_truth)
conf_matrix
```

#### Tune costing

```{r set training data}
set.seed(123)
intrain <- createDataPartition(y = d.ess9_supportvec$scale_cat, p= 0.7, list = FALSE) 
training <- d.ess9_supportvec[intrain,]
testing <- d.ess9_supportvec[-intrain,]
#training[["scale_cat"]] = factor(training[["scale_cat"]] != 0) 
#testing[["scale_cat"]] = factor(testing[["scale_cat"]] != 0)
```

```{r}
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
svm_linear <- train(scale_cat ~., data = training, method = "svmLinear",
                    trControl=trctrl,
                    preProcess = c("center", "scale"),
                    tuneLength = 10)
```

```{r}
grid <- expand.grid(
  C = c(0,0.01, 0.05, 0.1, 0.25, 0.5,
  0.75, 1, 1.25, 1.5, 1.75, 2,5))
svm_linear_grid <- train(
  scale_cat ~., data = train, method = "svmLinear",
  trControl=trctrl,
  preProcess = c("center", "scale"),
  tuneGrid = grid,
  tuneLength = 10
)
plot(svm_linear_grid)
```

```{r}
test_pred_grid <- predict(svm_linear_grid, newdata = testing)
test_pred_grid
confusionMatrix(table(test_pred_grid, testing$scale_cat))
```

**Interpretation**: The classification of the political affiliation can surpass the 50% accuracy mark but much more is not achievable. This model is not made for the kernel = linear but rather kernel = radial. It is a much more complex data and it needs to be treated that way.
