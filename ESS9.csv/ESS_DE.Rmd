---
title: "European Survey - What is the political sentiment in German speaking Countries
  Before Covid?"
author: "Milica Pajkic and Marco Rieder"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_document:
    toc: yes
    toc_depth: 5
code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
```

# Getting the Data and installing libraries

```{r, include=FALSE}
library(lubridate)
library(multcomp)
library(dplyr)
library(readr)
library(data.table)
library(tidyverse)
theme_set(theme_bw())
library(naniar)
library(neuralnet)
library(nnet)
library(caret)
library(gamlss.add)
library(ggplot2)
library(mgcv)

```

```{r data import}
ess9 <- read_csv("ESS9.csv")

unique(ess9$name)
unique(ess9$gndr)
unique(ess9$cntry)
```

```{r making subsets of the whole dataset to only german speaking countries}
ess9_de <- subset(ess9, cntry == "DE", select =dweight:domain)
ess9_ch <- subset(ess9, cntry == "CH", select =dweight:domain)
ess9_at <- subset(ess9, cntry == "AT", select =dweight:domain)
```

# 1. Introduction

The European Social Survey (ESS) is a large scale survey conducted in over 38 countries within Europe. Focusing on public attitudes and values and changes within time. This paper is evaluating the ninth version of the survey (ESS9) form 2018.

## 1.1 Selection of parameters

The survey is really comprehensive and consists out of 572 variables. Some of them are related to others and only answered by a subset of participants. 

## 1.2 Goal

# 2. Descriptive Statistics

First 

```{r }
summary(ess9$nwspol)
sum(is.na(ess9$nwspol))
```

```{r echo=FALSE}
summary(ess9_de$gndr)
sum(is.na(ess9_de$gndr))
typeof(ess9_de$nwspol)
```

```{r}
ggplot(ess9_de, aes(nwspol, 1)) +
  geom_bar(stat = "identity") + 
  xlim(c(0, 200))
```

```{r}
boxplot(ess9_de$nwspol, outline=FALSE)
```

### **Was muss man alles fÃ¼r eine deskriptive Analyse machen?**

```{r lineare Regression}
typeof(ess9_de$eduade3)
summary(ess9_de$eduade3)
sum(is.na(ess9_de$eduade3))
```

# 3. Models

## 3.1 Linear Model

How much politics are you watching = DV\
education level by years = IV\
happy with government = IV\
Gender = IV\
Age = IV


```{r linear Regression}
lm_news.1 <- lm(nwspol ~ eduade3, data = ess9_de)
summary(lm_news.1)
```

## 3.2 GLM Poisson

The goal of this chapter is to apply a generalized linear model of the poisson type on the ESS9 data set. 
The poisson model is applied to count data, in this case the information of how many minutes the participants spend per day for consuming media, such as newspaper, TV new shows or online resources. 
In this chapter the model is used to simulate the data, based on the provided data from the survey. 
First the data is cleaned and prepared for using it. A subset of the data is used, containing variables which should help to model the news consumption of a person. 
These parameters are used:
Depended variable: 

* How much politics are you watching ("nwspol")
Independent variables:

* Interest in politics ("polintr)
* Trust into the current parlament ("trstprl")
* Highest level of education ("eisced")
* Years of education ("eduyrs")
* Satisfaction with the general economical situation ("stfeco")
* Satisfaction with the current government ("stfgov")
* Gender ("gndr")
* Age ("agea")
* Level of person religion believe ("rlgdgr")
* Time spent online ("netusoft")
* Posibility for political participation ("psppsgva")
* Yearly gross income (combination of two factors into a new one - "yrpy")


### 3.2.1 Data preparation
The data have to be prepared and transformed. For poisson count data are needed for the predictive variable. The time in minutes is modeled therefore. 


```{r data preparation for models, include=TRUE}
# Setting NA values correct for the used parameters replace with NA replace function from naniar package. As each variable has a different NA setting, it is specified for each variable.

ess9_prep <- ess9 %>%
  replace_with_na(replace = list(nwspol =
                                   c(6666, 7777, 8888, 9999),
                                 polintr = c(7,8,9),
                                 trstprl = c(77,88,99),
                                 eisced = c(77,88,99),
                                 eduyrs = c(77, 88, 99),
                                 stfeco = c(77, 88, 99),
                                 stfgov = c(77, 88, 99),
                                 stfdem = c(77, 88, 99),
                                 gndr = 9,
                                 agea = 999,
                                 rlgdgr = c(77, 88, 99),
                                 netustm = c(6666, 7777, 8888, 9999),
                                 netusoft = c(7,8,9),
                                 psppsgva = c(7,8,9),
                                 grspnum = c(666666666,777777777,888888888,999999999),
                                 infqbst = c(6,7,8,9)
                                 
                                 ))

#testing if change has worked and how many NA we have - for four examples

sum(is.na(ess9_prep$nwspol))
sum(is.na(ess9_prep$eduyrs))
sum(is.na(ess9_prep$stfgov))
sum(is.na(ess9_prep$netusoft))

# The variable "grspnum" is depended on the variable "infqbst." As "infqbst" sets the period of the payment and "grpsnum" is the payment amount for the defined period. To standardize it on a yearly gross payment it needs a nested ifelse statement. If "infqbst" is one, we multiple it by 52 weeks of the year, if it is a two we multiple it by 12, and if it something else we keep it as it is (3 is already yearly payment, and values above will be filterd in the next step. 

ess9_prep$yrpy <- ifelse(ess9_prep$infqbst %in% 1,
                                ess9_prep$grspnum*52,  
                            ifelse(ess9_prep$infqbst %in% 2,
                                ess9_prep$grspnum*12, 
                                ess9_prep$grspnum))
```
Subset of data for this task, as 14 parameters in total. The rows with NA are dropped, as the data set is large enough for droping theses values.

```{r data subset and NA, include=TRUE}
# defining subset for study and models. These factors will be used in the Poisson and Neural Network models below. 
ess9_subset <- c("nwspol", "polintr", "trstprl", "eisced", "eduyrs","stfeco", "stfgov", "stfdem", "gndr", "agea","rlgdgr","netusoft", "psppsgva", "yrpy")

#subsetting the dataset with the defined parameters
ess9_prep <- ess9_prep[ess9_subset]

# drop NA for the columns used for the poisson model
ess9_prep <- ess9_prep %>% drop_na((ess9_subset))

#keep data for AMM part as numeric values - saved for later
ess9_prep_num <- ess9_prep
```


```{r data factorization, include=TRUE}
# set of parameters which are categorical variables
factors <- c("polintr","trstprl", "eisced", "stfeco", "stfgov", "stfdem", "gndr", "rlgdgr", "psppsgva", "netusoft")

# applying factorization of variables
ess9_prep[factors] <- lapply(ess9_prep[factors], as.factor)
#show data after preparation
str(ess9_prep)

```

The plot shows the media consumption for male and female. Males have a higher mean and the variance of the first and third quantile are larger.
```{r plotting of media consumaption}
# Use cleaned and factorized data for the Poisson model
ess9_poisson <- ess9_prep

ggplot(data = ess9_poisson, mapping = aes(y = nwspol,x = gndr)) +
  geom_boxplot() +
  ggtitle("Media consumption in minutes compared to Gender (Zoomed In)")+
  ylab("media consumption in minutes") +
  xlab("Gender") +
  coord_cartesian(ylim = quantile(ess9_poisson$nwspol, c(0.1, 0.9))) # large outliers are cropt out to indicate variance of male and female

```

### 3.2.2 Fitting the poisson model
Using the parameter specified above to model the consumption. 

```{r Poisson model fitting}
# fitting the model
glmP_news <- glm(nwspol ~ polintr + eisced + trstprl+ eduyrs + netusoft + stfeco + stfgov +
                   stfdem + gndr + agea + rlgdgr +yrpy,
                 family = "poisson", ## we specify the distribution!
                 data = ess9_poisson)

summary(glmP_news)

coef(glmP_news)

exp(coef(glmP_news)["(Intercept)"])

```

### 3.2.3 Simulation
Now we simulate with our model the average media consumption for Females and Males.
```{r poisson simulation of data}


set.seed(2) # for reproducibility
#simulate the data from glm poisson
sim.data.ess9.Poisson <- simulate(glmP_news)
##

NROW(sim.data.ess9.Poisson)
head(sim.data.ess9.Poisson)

#plot data as bar plot, with gender as factor to get two groups to compare, without factoring only one plot would show.
ggplot(mapping = aes(y = sim.data.ess9.Poisson$sim_1,
                     x = ess9_poisson$gndr)) +
  geom_boxplot() +
  geom_hline(yintercept = 0) +
  ylab("simulated media consumption \n(assuming Poisson dist)") +
  xlab("Gender") +
  coord_cartesian(ylim = quantile(ess9_poisson$nwspol, c(0.1, 0.9))) # large outliers are removed to indicate variance of male and female

```
The simulated data look similar as the real data based of the survey. The variance is smaller for the simulated one. The higher mean and the higher variance for the male group is indicated in the real data as well as in the simulated data. 

### 3.2.4 GLM Quasi-Poisson
```{r quasipoisson}
glmQ_news <- glm(nwspol ~ polintr + eisced + trstprl+ eduyrs + netusoft + stfeco + stfgov +
                   stfdem + gndr + agea + rlgdgr +yrpy,
                 family = "quasipoisson", ## we specify the distribution!
                 data = ess9_poisson)
summary(glmQ_news)
```


```{r quasipoisson - Anova for Gender}

# Checking if Gender plays a role in the quasipoisson model. With the ANOVA function.
glmQ_news_noGender <- update(glmQ_news, . ~ . - gndr)
anova(glmQ_news, glmQ_news_noGender, test = "F")
```
Yes, Gender plays a role for the quasi poisson model. 

```{r quasipoisson - Anova for stfdem}

# Checking if Gender plays a role in the quasipoisson model. With the ANOVA function.
glmQ_news_noGender <- update(glmQ_news, . ~ . - stfdem)
anova(glmQ_news, glmQ_news_noGender, test = "F")
```
To compare it with the variable of "stfdem" about how satisfied the participants of the survey are about how the democracy in their country works. This variable doensn't play a role to predict the media consumption according to the quasipoisson model.


### Labs Example

```{r}

```


<<<<<<< HEAD:ESS9.csv/ESS_DE.Rmd
## 3.3 GLM Binominal
=======
```{r}

```


## 3.3 GLM Binominal 
>>>>>>> d33abb64bd4520b2c184cf8af74b866bfe227af9:ESS9.csv/rfile/ESS_DE.Rmd

## 3.4 GAM

In this chapter a generalized additive model (GAM) is applied to the data set. First the data is visually analyzed and checked. The variables don't show a strong relation ship and the line is mostly horizontal.

```{r GAM peperation}
ess9_GAM <- ess9_prep

# Multi plots for News Consumption

pairs((nwspol) ~ . , data = ess9_GAM, pch = ".", upper.panel = panel.smooth)
#plotting news consumption and highest level of education (standardized)
ggplot(data = ess9_GAM ,mapping = aes(y = nwspol ,
                                  x = eisced)) +
  geom_boxplot()


# ploting news and age of participants
ggplot(data = ess9_GAM ,mapping = aes(y = nwspol ,
                                  x =  (agea))) +
  geom_point()+
  geom_smooth()

#plotting news and education

ggplot(data = ess9_GAM ,mapping = aes(y = nwspol ,
                                  x =  (eduyrs))) +
  geom_point()+
  geom_smooth()


ggplot(data = ess9_GAM ,mapping = aes(y = nwspol ,
                                  x =  (yrpy))) +
  geom_point()+
  geom_smooth()
```


```{r GAM}
GAM.netusoft <- gam((as.numeric(netusoft)) ~ yrpy + 
                      s(nwspol) + s(agea) + 
                      s(eduyrs, k= 1),
                data = ess9_poisson)
plot(GAM.netusoft, residuals = TRUE, cex = 2)
```
```{r}
GAM.netusoft2 <- gam((as.numeric(netusoft)) ~ yrpy + 
                      s(nwspol) + s(agea) + 
                      eduyrs,
                data = ess9_poisson)

plot(GAM.netusoft2, residuals = TRUE, cex = 2)

```


## 3.5 Neural Network 

Within this chapter two types of neural network model are applied to two different questions. 

1. Predicting the values for the continuous variable 
2. Predicting the vallues for the categorical variable inidicating the 5 levels of 
### 3.5.1 continious variable


```{r data import for neural network}

ess9_ann<- ess9_prep_num

str(ess9_ann)

```


#### Prepare for Training

```{r preparation}
set.seed(123)
ess9_ann[factors] <- lapply(ess9_ann[factors], as.numeric)

indices <- createDataPartition(ess9_ann$nwspol, p = 0.8, list = FALSE)
train <- ess9_ann %>% slice(indices)
test <- ess9_ann %>% slice(-indices)
boxplot(train$nwspol, test$nwspol, ess9_ann %>% sample_frac(0.2) %>% pull(nwspol), outline = FALSE)
```


```{r scaling of data}
max <- apply(ess9_ann, 2, max)
min <- apply(ess9_ann, 2, min)
ess9_ann_scaled <- as.data.frame(scale(ess9_ann, center = min, scale = max - min))
train_scaled <- ess9_ann_scaled %>% slice(indices)
test_scaled <- ess9_ann_scaled %>% slice(-indices)
```

#### Fit the Network

```{r NN model fitting}


set.seed(42)
ess9_nnet = neuralnet(nwspol ~ polintr + eisced + trstprl+ eduyrs + netusoft + 
                        stfeco + stfgov + stfdem + gndr + agea + rlgdgr +yrpy,
                      train_scaled, hidden = 3 , linear.output = FALSE)
plot(ess9_nnet)
```
#### Predict the test set

```{r predict, include=FALSE}
pred_scaled <- compute(ess9_nnet, test_scaled %>% select(-nwspol))
pred <- pred_scaled$net.result * (max(ess9_ann$nwspol) - min(ess9_ann$nwspol)) + min(ess9_ann$nwspol)
pred
```


```{r plot comparsion of real and predicated data}
plot(test$nwspol, pred, col='blue', pch=16, ylab = "predicted nwspol NN", xlab = "real nwspol")
abline(0,1)
```
And calculate the RMSE
```{r RMSE}
sqrt(mean((test$nwspol - pred)^2))
```

#### Redo with `caret` and Cross Validation

```{r caret applied again, include=FALSE, message=FALSE, warning=FALSE}
set.seed(42)
tuGrid <- expand.grid(.layer1=c(1:1), .layer2=c(0,2), .layer3=c(0))


trCtrl <- trainControl(
  method = 'repeatedcv', 
  number = 4, 
  repeats = 8, 
  returnResamp = 'final'
)

models <- train(
  x = ess9_ann %>% select(-nwspol),
  y = ess9_ann_scaled %>% pull(nwspol),
  method = 'neuralnet', metric = 'RMSE', 
  linear.output = FALSE,
  # be careful, does only work on x!
  preProcess = c('center', 'scale'),
  tuneGrid = tuGrid,
  trControl = trCtrl
)
```


```{r message=FALSE, warning=FALSE}
plot(test$nwspol, pred, col='blue', pch=16, ylab = "predicted rating NN", xlab = "real rating")
abline(0,1)
```

```{r}
plot(models)


#and extract the best model

plot(models$finalModel)
```

### 3.5.2 Categorical variable

```{r}
ess9_ann2<- ess9_prep_num

ess9_ann2$netusoft <- as.factor(ess9_ann2$netusoft)


str(ess9_ann2)
```
#### Have a quick look at the Data

```{r}
ess9_ann2 %>%
  ggplot(aes(x = yrpy, y = nwspol, color = netusoft)) +
  geom_point()
```

```{r}
ess9_ann2 %>%
  ggplot(aes(x = eduyrs, y = nwspol, color = netusoft)) +
  geom_point()
```

#### Prepare the Data for Training

```{r}
set.seed(123)
indices <- createDataPartition(ess9_ann2$netusoft, p=.85, list = F)
```

#### Why do we use the `caret` function

Look at the distribution of our different prediction classes in the train and test datasets:

```{r}
ess9_ann2 %>%
  mutate(train = row_number() %in% indices) %>%
  select(netusoft, train) %>%
  table()
```
Now compare this to the "random" approach:

```{r}
ess9_ann2 %>%
  mutate(train = runif(nrow(ess9_ann2)) < .85) %>%
  select(netusoft, train) %>%
  table()
```
So using the `createDataPartition` function makes sure that no class is over- or underrepresented relative to the total occurance in the two sets

#### Create some easy Variables to access Data

```{r}
train <- ess9_ann2 %>%
  slice(indices)
test_in <- ess9_ann2 %>%
  slice(-indices) %>%
  select(-netusoft)
test_truth <- ess9_ann2 %>%
  slice(-indices) %>%
  pull(netusoft)
```

#### Train the Neural Network

Call the `neuralnet` function creating a network with two hidden layers containing 4 and 3 neurons (probably way too complex for our problem here).

```{r}
set.seed(21)
ess9_ann_net <- neuralnet(netusoft ~ ., train, hidden = c(2,1))
```

Plot the resulting network including the weights

```{r}
plot(ess9_ann_net)
```
#### Make Predictions

```{r Predictions, include=FALSE}
test_results <- neuralnet::compute(ess9_ann_net, test_in)
test_results$net.result
```

Find class (i.e. output neuron) with the highest probability and convert this back into a factor

```{r find class, include=FALSE}
test_pred <- apply(test_results$net.result, 1, which.max)
test_pred <- factor(levels(test_truth)[test_pred], levels = levels(test_truth))
test_pred
```
#### Evaluate the Results

```{r conf matrix}
conf_matrix <- confusionMatrix(test_truth, test_pred)
conf_matrix
```
#### Optimize Network Structure

First we need to remodel the data due to some limitations of `caret`

```{r}
xor <- model.matrix(~ netusoft, ess9_ann2)
xor[,1] <- ifelse(xor[,2] %in% 0 & xor[,3] %in% 0, 1, 0)
colnames(xor)[1] <- 'netusoft'
head(xor)

ess9_ann_mod <- cbind(xor, ess9_ann2 %>% select(-netusoft))
train_mod <- ess9_ann_mod %>% slice(indices)
```


```{r}

set.seed(142)
formula = netusoft + netusoft2 + netusoft3 + netusoft4 + netusoft5 ~ nwspol + stfdem + gndr + agea + yrpy + eduyrs
models <- train(formula, train_mod,
               method="neuralnet",
               linear.output = FALSE,
               ### Parameters for layers
               tuneGrid = expand.grid(.layer1=c(1:2), .layer2=c(0:3), .layer3=c(0)),  
               ### Parameters for optmisation
               learningrate = 0.1,  
               threshold = 0.1,     
               stepmax = 5000         
)

```
And have a look at the different models

```{r}
plot(models)

```


And try out the best model

```{r}
set.seed(42)
best_model <- neuralnet(
  formula,
  ess9_ann_mod %>% slice(indices),
  hidden = c(2,3),
  learningrate = 0.1, 
  threshold = 0.1,   
  stepmax = 20000,
  linear.output = FALSE
)

plot(best_model)

```

## 3.6 Support Vector Machine
